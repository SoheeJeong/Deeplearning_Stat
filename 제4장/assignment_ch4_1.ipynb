{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1번\n",
    "CNN 모형에서 mnist데이터의  pixel 의 size 가 maxpooling 에 의해 줄어들 때, channel 수를 maxpooling 의 kernel size 만큼 증가시켜 원래 모형과 비교하라."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mnist 데이터 불러오고 reshape 하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.utils import to_categorical, plot_model\n",
    "from tensorflow.keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train,y_train),(x_test,y_test)=mnist.load_data()\n",
    "num_labels=len(np.unique(y_train))\n",
    "y_train=to_categorical(y_train)\n",
    "y_test=to_categorical(y_test)\n",
    "\n",
    "shape1=x_train.shape[1]\n",
    "shape2=x_train.shape[2]\n",
    "\n",
    "#cnn 에 쓸 수 있도록 4D tensor 로 reshape 한다.\n",
    "x_train=x_train.reshape(-1, shape1,shape2,1).astype('float32')\n",
    "x_test=x_test.reshape(-1, shape1,shape2,1).astype('float32')\n",
    "x_train=x_train/255.\n",
    "x_test=x_test/255.\n",
    "\n",
    "#표본수를 포함하여 4D 텐서이므로 입력은 3D 텐서가 된다.\n",
    "input_shape=(shape1,shape2,1)\n",
    "batch_size=64 # batch size를 정해놓음\n",
    "kernel_size=3\n",
    "pool_size=2\n",
    "filters=64\n",
    "dropout=0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN 모델 생성 - Sequential API|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**기존 모형) kernel size = 2 인 max_pooling 을 적용함**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 64)        640       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 11, 11, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 3, 3, 64)          36928     \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 576)               0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 576)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                5770      \n",
      "=================================================================\n",
      "Total params: 80,266\n",
      "Trainable params: 80,266\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=Sequential()\n",
    "model.add(Conv2D(filters=filters,kernel_size=kernel_size,activation='relu',input_shape=input_shape))\n",
    "# kernel size = 2인 max_pooling\n",
    "model.add(MaxPooling2D(pool_size))\n",
    "model.add(Conv2D(filters=filters,kernel_size=kernel_size,activation='relu'))\n",
    "# kernel size = 2인 max_pooling\n",
    "model.add(MaxPooling2D(pool_size))\n",
    "model.add(Conv2D(filters=filters,kernel_size=kernel_size,activation='relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(dropout))\n",
    "model.add(Dense(num_labels, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "938/938 [==============================] - 56s 58ms/step - loss: 0.4675 - accuracy: 0.85211s - loss: 0.4738 - accuracy:  - ETA: \n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 57s 61ms/step - loss: 0.0655 - accuracy: 0.9786\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 58s 62ms/step - loss: 0.0469 - accuracy: 0.9852\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 56s 60ms/step - loss: 0.0356 - accuracy: 0.9883\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 60s 64ms/step - loss: 0.0289 - accuracy: 0.9909\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 59s 62ms/step - loss: 0.0257 - accuracy: 0.9920\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 62s 67ms/step - loss: 0.0199 - accuracy: 0.9931\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 66s 70ms/step - loss: 0.0177 - accuracy: 0.9937\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 64s 68ms/step - loss: 0.0166 - accuracy: 0.9950\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 63s 67ms/step - loss: 0.0146 - accuracy: 0.9954\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1c8e2dc0100>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy',optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(x_train,y_train,epochs=10,batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 3s 31ms/step - loss: 0.0239 - accuracy: 0.9925  - ETA: 0s - loss: 0.0242 - accuracy: 0.\n",
      "[0.023880712687969208, 0.9925000071525574]\n"
     ]
    }
   ],
   "source": [
    "results=model.evaluate(x_test,y_test, batch_size=128)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**새로운 모형) maxpooling 이후 1X1 convolution layer를 추가해 channel 수를 늘림**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_6 (Conv2D)            (None, 26, 26, 64)        640       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 13, 13, 128)       8320      \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 11, 11, 64)        73792     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 5, 5, 128)         8320      \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 3, 3, 64)          73792     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 576)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 576)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                5770      \n",
      "=================================================================\n",
      "Total params: 170,634\n",
      "Trainable params: 170,634\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten\n",
    "\n",
    "new_model=Sequential()\n",
    "new_model.add(Conv2D(filters=filters,kernel_size=kernel_size,activation='relu',input_shape=input_shape))\n",
    "new_model.add(MaxPooling2D(pool_size)) # kernel size = 2인 max_pooling\n",
    "new_model.add(Conv2D(filters=filters*pool_size,kernel_size=1)) # channel 수를 pool_size 만큼 늘림\n",
    "new_model.add(Conv2D(filters=filters,kernel_size=kernel_size,activation='relu'))\n",
    "new_model.add(MaxPooling2D(pool_size)) # kernel size = 2인 max_pooling\n",
    "new_model.add(Conv2D(filters=filters*pool_size,kernel_size=1)) # channel 수를 pool_size 만큼 늘림\n",
    "new_model.add(Conv2D(filters=filters,kernel_size=kernel_size,activation='relu'))\n",
    "new_model.add(Flatten())\n",
    "new_model.add(Dropout(dropout))\n",
    "new_model.add(Dense(num_labels, activation='softmax'))\n",
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "938/938 [==============================] - 94s 100ms/step - loss: 0.3859 - accuracy: 0.8742\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 96s 102ms/step - loss: 0.0611 - accuracy: 0.9815\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 101s 108ms/step - loss: 0.0429 - accuracy: 0.9869\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 97s 104ms/step - loss: 0.0362 - accuracy: 0.9887\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 92s 98ms/step - loss: 0.0313 - accuracy: 0.9904\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 88s 94ms/step - loss: 0.0284 - accuracy: 0.9913\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 85s 91ms/step - loss: 0.0247 - accuracy: 0.9917\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 88s 94ms/step - loss: 0.0230 - accuracy: 0.9930\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 87s 93ms/step - loss: 0.0202 - accuracy: 0.9933\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 86s 92ms/step - loss: 0.0194 - accuracy: 0.9939\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1c8e453fbb0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model.compile(loss='categorical_crossentropy',optimizer='adam', metrics=['accuracy'])\n",
    "new_model.fit(x_train,y_train,epochs=10,batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 3s 39ms/step - loss: 0.0254 - accuracy: 0.9926\n",
      "[0.025436801835894585, 0.9926000237464905]\n"
     ]
    }
   ],
   "source": [
    "results=new_model.evaluate(x_test,y_test, batch_size=128)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2번"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(1) Boston-housing 데이터를 tensorflow dataset API 에서 내려받아, traing data 와 test data 를 구성하라.\n",
    "\n",
    "(2) Boston-housing 데이터를 그림 4-1 아키텍쳐에 적용한 후, 모형의 최적화를 callbacks 로 구현하라."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boston Housing data 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float64 float64\n",
      "(404, 13) (404,)\n",
      "(102, 13)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import boston_housing\n",
    "\n",
    "(x_train,y_train),(x_test,y_test) = boston_housing.load_data()\n",
    "print(x_train.dtype,y_train.dtype)\n",
    "print(x_train.shape,y_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "input data를 각각 10개의 특성변수를 갖도록 하며 2개로 나눔 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train1, x_train2 = x_train[:,:10], x_train[:,3:]\n",
    "x_test1, x_test2 =  x_test[:,:10], x_test[:,3:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 그림 4-1 아키텍처와 같은 모델 생성 - Functional API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 10)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 16)           176         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 16)           272         dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 10)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 26)           0           input_2[0][0]                    \n",
      "                                                                 dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 1)            17          dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 1)            27          concatenate[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 492\n",
      "Trainable params: 492\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input,Dense,concatenate\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "input_A=Input(shape=[10])\n",
    "input_B=Input(shape=[10])\n",
    "h1=Dense(16,activation='relu')(input_A) #그림 4-1에서 dense1에 해당\n",
    "h2=Dense(16,activation='relu')(h1) #dense2에 해당\n",
    "concat=concatenate([input_B,h2]) #inputB와 h2를 연결. concatenate.\n",
    "out1=Dense(1)(h2) #output 하나를 꺼내고\n",
    "out2=Dense(1)(concat) #concat 해서 output2를 만듦\n",
    "model=Model(inputs=[input_A,input_B],outputs=[out1,out2])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### callback 함수로 EarlyStopping 과 ModelCheckpoint 를 사용\n",
    "compile & fit\n",
    "* epoch를 200으로 충분히 크게 하고 earlystopping을 patience=10으로 적용하였다.\n",
    "* val_loss 를 earlystopping의 기준으로 설정하였다.\n",
    "* ModelCheckpoint를 통해 val_loss 가 가장 작은 model을 저장하였다.\n",
    "* batch size는 64로 하였다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "7/7 [==============================] - 5s 566ms/step - loss: 54058.5347 - dense_2_loss: 27001.9387 - dense_3_loss: 60822.6880 - val_loss: 39906.5742 - val_dense_2_loss: 17924.1836 - val_dense_3_loss: 45402.1680\n",
      "Epoch 2/200\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 35181.1694 - dense_2_loss: 15712.7874 - dense_3_loss: 40048.2651 - val_loss: 27944.5000 - val_dense_2_loss: 11421.1396 - val_dense_3_loss: 32075.3398\n",
      "Epoch 3/200\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 24698.9937 - dense_2_loss: 9875.8508 - dense_3_loss: 28404.7803 - val_loss: 18929.1270 - val_dense_2_loss: 6739.5762 - val_dense_3_loss: 21976.5156\n",
      "Epoch 4/200\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 16802.3304 - dense_2_loss: 5923.9451 - dense_3_loss: 19521.9265 - val_loss: 12288.4170 - val_dense_2_loss: 3670.1807 - val_dense_3_loss: 14442.9766\n",
      "Epoch 5/200\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 10686.8329 - dense_2_loss: 3166.9863 - dense_3_loss: 12566.7952 - val_loss: 8220.2363 - val_dense_2_loss: 2176.1577 - val_dense_3_loss: 9731.2549\n",
      "Epoch 6/200\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 7210.7375 - dense_2_loss: 1930.4815 - dense_3_loss: 8530.8015 - val_loss: 5141.0869 - val_dense_2_loss: 1236.2039 - val_dense_3_loss: 6117.3076\n",
      "Epoch 7/200\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 4456.3525 - dense_2_loss: 1068.8524 - dense_3_loss: 5303.2274 - val_loss: 2978.9761 - val_dense_2_loss: 719.1667 - val_dense_3_loss: 3543.9282\n",
      "Epoch 8/200\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 2508.2478 - dense_2_loss: 640.8220 - dense_3_loss: 2975.1042 - val_loss: 1564.3365 - val_dense_2_loss: 496.3414 - val_dense_3_loss: 1831.3352\n",
      "Epoch 9/200\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 1392.1772 - dense_2_loss: 509.9463 - dense_3_loss: 1612.7349 - val_loss: 827.6699 - val_dense_2_loss: 444.6998 - val_dense_3_loss: 923.4124\n",
      "Epoch 10/200\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 766.1839 - dense_2_loss: 450.5729 - dense_3_loss: 845.0866 - val_loss: 559.1301 - val_dense_2_loss: 441.1675 - val_dense_3_loss: 588.6207\n",
      "Epoch 11/200\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 559.6023 - dense_2_loss: 446.3247 - dense_3_loss: 587.9216 - val_loss: 486.4880 - val_dense_2_loss: 427.7882 - val_dense_3_loss: 501.1629\n",
      "Epoch 12/200\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 491.1675 - dense_2_loss: 430.7688 - dense_3_loss: 506.2671 - val_loss: 452.0697 - val_dense_2_loss: 414.3403 - val_dense_3_loss: 461.5020\n",
      "Epoch 13/200\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 469.2668 - dense_2_loss: 434.7511 - dense_3_loss: 477.8957 - val_loss: 424.3454 - val_dense_2_loss: 403.6346 - val_dense_3_loss: 429.5232\n",
      "Epoch 14/200\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 416.7369 - dense_2_loss: 384.2994 - dense_3_loss: 424.8462 - val_loss: 388.4474 - val_dense_2_loss: 388.3398 - val_dense_3_loss: 388.4744\n",
      "Epoch 15/200\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 384.8151 - dense_2_loss: 375.3271 - dense_3_loss: 387.1870 - val_loss: 346.4924 - val_dense_2_loss: 366.1776 - val_dense_3_loss: 341.5711\n",
      "Epoch 16/200\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 362.2803 - dense_2_loss: 391.6623 - dense_3_loss: 354.9347 - val_loss: 296.6621 - val_dense_2_loss: 338.4740 - val_dense_3_loss: 286.2092\n",
      "Epoch 17/200\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 284.3386 - dense_2_loss: 326.2592 - dense_3_loss: 273.8584 - val_loss: 285.0540 - val_dense_2_loss: 361.8612 - val_dense_3_loss: 265.8522\n",
      "Epoch 18/200\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 272.6785 - dense_2_loss: 338.3579 - dense_3_loss: 256.2586 - val_loss: 232.4472 - val_dense_2_loss: 302.2725 - val_dense_3_loss: 214.9908\n",
      "Epoch 19/200\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 223.6209 - dense_2_loss: 302.1162 - dense_3_loss: 203.9971 - val_loss: 197.8592 - val_dense_2_loss: 282.3209 - val_dense_3_loss: 176.7438\n",
      "Epoch 20/200\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 193.2455 - dense_2_loss: 284.2118 - dense_3_loss: 170.5040 - val_loss: 180.9373 - val_dense_2_loss: 283.6137 - val_dense_3_loss: 155.2682\n",
      "Epoch 21/200\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 167.9469 - dense_2_loss: 269.3832 - dense_3_loss: 142.5878 - val_loss: 152.0021 - val_dense_2_loss: 250.2319 - val_dense_3_loss: 127.4446\n",
      "Epoch 22/200\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 166.8221 - dense_2_loss: 258.4728 - dense_3_loss: 143.9094 - val_loss: 140.3979 - val_dense_2_loss: 239.1569 - val_dense_3_loss: 115.7082\n",
      "Epoch 23/200\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 139.6783 - dense_2_loss: 233.9543 - dense_3_loss: 116.1092 - val_loss: 126.1622 - val_dense_2_loss: 227.0861 - val_dense_3_loss: 100.9312\n",
      "Epoch 24/200\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 125.9157 - dense_2_loss: 228.2928 - dense_3_loss: 100.3214 - val_loss: 122.0438 - val_dense_2_loss: 236.3796 - val_dense_3_loss: 93.4599\n",
      "Epoch 25/200\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 127.2317 - dense_2_loss: 232.6318 - dense_3_loss: 100.8817 - val_loss: 111.1525 - val_dense_2_loss: 198.2940 - val_dense_3_loss: 89.3672\n",
      "Epoch 26/200\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 114.1930 - dense_2_loss: 210.9417 - dense_3_loss: 90.0058 - val_loss: 138.6458 - val_dense_2_loss: 202.5051 - val_dense_3_loss: 122.6809\n",
      "Epoch 27/200\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 126.6109 - dense_2_loss: 203.6563 - dense_3_loss: 107.3495 - val_loss: 100.5184 - val_dense_2_loss: 183.5076 - val_dense_3_loss: 79.7710\n",
      "Epoch 28/200\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 98.8485 - dense_2_loss: 178.9620 - dense_3_loss: 78.8201 - val_loss: 100.4826 - val_dense_2_loss: 173.1139 - val_dense_3_loss: 82.3248\n",
      "Epoch 29/200\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 94.5163 - dense_2_loss: 169.4231 - dense_3_loss: 75.7896 - val_loss: 96.3668 - val_dense_2_loss: 161.1078 - val_dense_3_loss: 80.1815\n",
      "Epoch 30/200\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 89.4666 - dense_2_loss: 156.3874 - dense_3_loss: 72.7364 - val_loss: 113.4103 - val_dense_2_loss: 163.1059 - val_dense_3_loss: 100.9865\n",
      "Epoch 31/200\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 93.9613 - dense_2_loss: 147.3437 - dense_3_loss: 80.6157 - val_loss: 92.3284 - val_dense_2_loss: 150.6026 - val_dense_3_loss: 77.7598\n",
      "Epoch 32/200\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 97.7517 - dense_2_loss: 145.9773 - dense_3_loss: 85.6953 - val_loss: 85.7236 - val_dense_2_loss: 140.3255 - val_dense_3_loss: 72.0731\n",
      "Epoch 33/200\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 86.7014 - dense_2_loss: 134.5298 - dense_3_loss: 74.7443 - val_loss: 94.5759 - val_dense_2_loss: 151.6893 - val_dense_3_loss: 80.2975\n",
      "Epoch 34/200\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 90.3559 - dense_2_loss: 140.8836 - dense_3_loss: 77.7240 - val_loss: 95.7263 - val_dense_2_loss: 147.2254 - val_dense_3_loss: 82.8516\n",
      "Epoch 35/200\n",
      "7/7 [==============================] - 0s 49ms/step - loss: 91.9887 - dense_2_loss: 130.7113 - dense_3_loss: 82.3081 - val_loss: 92.0349 - val_dense_2_loss: 124.2804 - val_dense_3_loss: 83.9735\n",
      "Epoch 36/200\n",
      "7/7 [==============================] - 0s 42ms/step - loss: 84.9676 - dense_2_loss: 116.5513 - dense_3_loss: 77.0717 - val_loss: 96.7157 - val_dense_2_loss: 122.2862 - val_dense_3_loss: 90.3230\n",
      "Epoch 37/200\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 91.5050 - dense_2_loss: 118.4710 - dense_3_loss: 84.7635 - val_loss: 91.8434 - val_dense_2_loss: 121.2207 - val_dense_3_loss: 84.4990\n",
      "Epoch 38/200\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 90.2134 - dense_2_loss: 114.9373 - dense_3_loss: 84.0324 - val_loss: 78.4289 - val_dense_2_loss: 111.4561 - val_dense_3_loss: 70.1721\n",
      "Epoch 39/200\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 89.4879 - dense_2_loss: 109.9310 - dense_3_loss: 84.3771 - val_loss: 81.7355 - val_dense_2_loss: 109.5133 - val_dense_3_loss: 74.7911\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/200\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 77.7320 - dense_2_loss: 97.7393 - dense_3_loss: 72.7302 - val_loss: 106.3453 - val_dense_2_loss: 113.2621 - val_dense_3_loss: 104.6161\n",
      "Epoch 41/200\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 81.0196 - dense_2_loss: 94.6361 - dense_3_loss: 77.6155 - val_loss: 76.3633 - val_dense_2_loss: 103.4674 - val_dense_3_loss: 69.5872\n",
      "Epoch 42/200\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 76.4444 - dense_2_loss: 99.1216 - dense_3_loss: 70.7751 - val_loss: 76.5330 - val_dense_2_loss: 109.1047 - val_dense_3_loss: 68.3901\n",
      "Epoch 43/200\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 85.9739 - dense_2_loss: 104.7767 - dense_3_loss: 81.2732 - val_loss: 75.4894 - val_dense_2_loss: 98.6287 - val_dense_3_loss: 69.7045\n",
      "Epoch 44/200\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 70.7114 - dense_2_loss: 90.4130 - dense_3_loss: 65.7860 - val_loss: 85.7641 - val_dense_2_loss: 97.4013 - val_dense_3_loss: 82.8547\n",
      "Epoch 45/200\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 74.8813 - dense_2_loss: 85.4253 - dense_3_loss: 72.2454 - val_loss: 89.2080 - val_dense_2_loss: 110.8936 - val_dense_3_loss: 83.7866\n",
      "Epoch 46/200\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 71.3945 - dense_2_loss: 84.5326 - dense_3_loss: 68.1100 - val_loss: 90.0902 - val_dense_2_loss: 118.1172 - val_dense_3_loss: 83.0835\n",
      "Epoch 47/200\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 83.6466 - dense_2_loss: 102.8436 - dense_3_loss: 78.8474 - val_loss: 82.0221 - val_dense_2_loss: 99.5347 - val_dense_3_loss: 77.6439\n",
      "Epoch 48/200\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 95.9521 - dense_2_loss: 103.0021 - dense_3_loss: 94.1896 - val_loss: 75.2197 - val_dense_2_loss: 90.6329 - val_dense_3_loss: 71.3664\n",
      "Epoch 49/200\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 67.8422 - dense_2_loss: 81.2651 - dense_3_loss: 64.4864 - val_loss: 69.9346 - val_dense_2_loss: 89.2002 - val_dense_3_loss: 65.1182\n",
      "Epoch 50/200\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 71.7327 - dense_2_loss: 85.3474 - dense_3_loss: 68.3290 - val_loss: 69.1421 - val_dense_2_loss: 88.3339 - val_dense_3_loss: 64.3441\n",
      "Epoch 51/200\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 73.8065 - dense_2_loss: 89.2228 - dense_3_loss: 69.9524 - val_loss: 67.2769 - val_dense_2_loss: 89.0573 - val_dense_3_loss: 61.8318\n",
      "Epoch 52/200\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 76.0450 - dense_2_loss: 86.6487 - dense_3_loss: 73.3941 - val_loss: 71.9391 - val_dense_2_loss: 86.4206 - val_dense_3_loss: 68.3187\n",
      "Epoch 53/200\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 78.5545 - dense_2_loss: 89.0741 - dense_3_loss: 75.9246 - val_loss: 73.4914 - val_dense_2_loss: 92.6826 - val_dense_3_loss: 68.6937\n",
      "Epoch 54/200\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 72.4098 - dense_2_loss: 85.7167 - dense_3_loss: 69.0830 - val_loss: 67.8968 - val_dense_2_loss: 86.4967 - val_dense_3_loss: 63.2468\n",
      "Epoch 55/200\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 67.3958 - dense_2_loss: 81.8929 - dense_3_loss: 63.7715 - val_loss: 91.4732 - val_dense_2_loss: 103.0292 - val_dense_3_loss: 88.5842\n",
      "Epoch 56/200\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 63.8663 - dense_2_loss: 75.5937 - dense_3_loss: 60.9345 - val_loss: 81.7517 - val_dense_2_loss: 98.8901 - val_dense_3_loss: 77.4671\n",
      "Epoch 57/200\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 72.3673 - dense_2_loss: 84.1899 - dense_3_loss: 69.4116 - val_loss: 88.9220 - val_dense_2_loss: 98.9542 - val_dense_3_loss: 86.4139\n",
      "Epoch 58/200\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 73.4894 - dense_2_loss: 82.8868 - dense_3_loss: 71.1401 - val_loss: 81.6286 - val_dense_2_loss: 87.8221 - val_dense_3_loss: 80.0803\n",
      "Epoch 59/200\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 78.6064 - dense_2_loss: 84.4699 - dense_3_loss: 77.1405 - val_loss: 67.2944 - val_dense_2_loss: 82.2155 - val_dense_3_loss: 63.5641\n",
      "Epoch 60/200\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 74.8115 - dense_2_loss: 85.9072 - dense_3_loss: 72.0376 - val_loss: 63.6146 - val_dense_2_loss: 80.4393 - val_dense_3_loss: 59.4084\n",
      "Epoch 61/200\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 68.1203 - dense_2_loss: 81.4887 - dense_3_loss: 64.7782 - val_loss: 73.5238 - val_dense_2_loss: 93.8612 - val_dense_3_loss: 68.4395\n",
      "Epoch 62/200\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 59.3727 - dense_2_loss: 72.0758 - dense_3_loss: 56.1970 - val_loss: 68.0853 - val_dense_2_loss: 85.1497 - val_dense_3_loss: 63.8192\n",
      "Epoch 63/200\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 78.0551 - dense_2_loss: 89.9480 - dense_3_loss: 75.0819 - val_loss: 64.5576 - val_dense_2_loss: 81.3871 - val_dense_3_loss: 60.3502\n",
      "Epoch 64/200\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 67.6679 - dense_2_loss: 76.9930 - dense_3_loss: 65.3366 - val_loss: 88.8582 - val_dense_2_loss: 97.9600 - val_dense_3_loss: 86.5827\n",
      "Epoch 65/200\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 95.8856 - dense_2_loss: 104.6653 - dense_3_loss: 93.6907 - val_loss: 66.7543 - val_dense_2_loss: 84.7847 - val_dense_3_loss: 62.2467\n",
      "Epoch 66/200\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 65.8238 - dense_2_loss: 79.6510 - dense_3_loss: 62.3670 - val_loss: 73.9775 - val_dense_2_loss: 87.6331 - val_dense_3_loss: 70.5636\n",
      "Epoch 67/200\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 70.7802 - dense_2_loss: 82.7101 - dense_3_loss: 67.7977 - val_loss: 64.2469 - val_dense_2_loss: 82.5959 - val_dense_3_loss: 59.6596\n",
      "Epoch 68/200\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 58.1386 - dense_2_loss: 68.9638 - dense_3_loss: 55.4323 - val_loss: 81.8286 - val_dense_2_loss: 88.0052 - val_dense_3_loss: 80.2844\n",
      "Epoch 69/200\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 69.0738 - dense_2_loss: 76.8142 - dense_3_loss: 67.1387 - val_loss: 72.1195 - val_dense_2_loss: 97.9565 - val_dense_3_loss: 65.6602\n",
      "Epoch 70/200\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 65.7203 - dense_2_loss: 81.8821 - dense_3_loss: 61.6798 - val_loss: 65.5714 - val_dense_2_loss: 78.2188 - val_dense_3_loss: 62.4095\n"
     ]
    }
   ],
   "source": [
    "#callbacks\n",
    "from tensorflow.keras.callbacks import EarlyStopping,ModelCheckpoint,TensorBoard\n",
    "callback_list = [EarlyStopping(monitor='val_loss',mode='min',patience=10),\n",
    "                 ModelCheckpoint(filepath='model_boston_1.h5',monitor='val_loss',save_best_only='True'),\n",
    "                TensorBoard(log_dir=\"./logs-1\")]\n",
    "\n",
    "#compile model\n",
    "model.compile(loss=['mse','mse'],loss_weights=[0.2,0.8], optimizer='RMSprop')\n",
    "#fit model\n",
    "history = model.fit([x_train1,x_train2],[y_train,y_train],epochs=200, batch_size=64, callbacks=callback_list,\n",
    "                    validation_data=([x_test1,x_test2],[y_test,y_test]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorboard로 결과 살펴보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ERROR: Timed out waiting for TensorBoard to start. It may still be running as pid 32412."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir {\"./logs-1\"} --port=8000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cf) callback 함수로 ReduceLROnPlateau 를 사용할 수도 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "13/13 [==============================] - 1s 33ms/step - loss: 4556.0460 - dense_4_loss: 15506.7233 - dense_5_loss: 1818.3764 - val_loss: 2269.6091 - val_dense_4_loss: 6755.5454 - val_dense_5_loss: 1148.1249\n",
      "Epoch 2/70\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 2142.3176 - dense_4_loss: 5148.4999 - dense_5_loss: 1390.7719 - val_loss: 1224.7067 - val_dense_4_loss: 2414.9353 - val_dense_5_loss: 927.1495\n",
      "Epoch 3/70\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 1243.5795 - dense_4_loss: 1849.3603 - dense_5_loss: 1092.1342 - val_loss: 777.9865 - val_dense_4_loss: 787.5747 - val_dense_5_loss: 775.5894\n",
      "Epoch 4/70\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 844.6578 - dense_4_loss: 634.2230 - dense_5_loss: 897.2664 - val_loss: 592.0190 - val_dense_4_loss: 373.5371 - val_dense_5_loss: 646.6395\n",
      "Epoch 5/70\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 750.7629 - dense_4_loss: 341.4003 - dense_5_loss: 853.1036 - val_loss: 485.9062 - val_dense_4_loss: 344.9626 - val_dense_5_loss: 521.1420\n",
      "Epoch 6/70\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 628.8344 - dense_4_loss: 290.3629 - dense_5_loss: 713.4522 - val_loss: 393.6747 - val_dense_4_loss: 323.4578 - val_dense_5_loss: 411.2289\n",
      "Epoch 7/70\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 448.6846 - dense_4_loss: 297.2108 - dense_5_loss: 486.5531 - val_loss: 325.1570 - val_dense_4_loss: 305.4207 - val_dense_5_loss: 330.0911\n",
      "Epoch 8/70\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 378.8132 - dense_4_loss: 281.7590 - dense_5_loss: 403.0767 - val_loss: 299.7037 - val_dense_4_loss: 294.8073 - val_dense_5_loss: 300.9278\n",
      "Epoch 9/70\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 356.6541 - dense_4_loss: 269.5901 - dense_5_loss: 378.4202 - val_loss: 253.5893 - val_dense_4_loss: 278.6506 - val_dense_5_loss: 247.3239\n",
      "Epoch 10/70\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 297.0370 - dense_4_loss: 244.8511 - dense_5_loss: 310.0835 - val_loss: 200.6705 - val_dense_4_loss: 262.3863 - val_dense_5_loss: 185.2415\n",
      "Epoch 11/70\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 244.0756 - dense_4_loss: 240.0058 - dense_5_loss: 245.0930 - val_loss: 187.8844 - val_dense_4_loss: 247.1035 - val_dense_5_loss: 173.0796\n",
      "Epoch 12/70\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 204.3987 - dense_4_loss: 215.5940 - dense_5_loss: 201.5999 - val_loss: 167.0732 - val_dense_4_loss: 234.9901 - val_dense_5_loss: 150.0940\n",
      "Epoch 13/70\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 194.3815 - dense_4_loss: 177.4419 - dense_5_loss: 198.6164 - val_loss: 154.3061 - val_dense_4_loss: 212.7851 - val_dense_5_loss: 139.6864\n",
      "Epoch 14/70\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 165.3028 - dense_4_loss: 177.8875 - dense_5_loss: 162.1566 - val_loss: 161.2868 - val_dense_4_loss: 187.6684 - val_dense_5_loss: 154.6914\n",
      "Epoch 15/70\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 147.9162 - dense_4_loss: 166.0531 - dense_5_loss: 143.3820 - val_loss: 146.2233 - val_dense_4_loss: 178.9330 - val_dense_5_loss: 138.0459\n",
      "Epoch 16/70\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 141.7899 - dense_4_loss: 147.8969 - dense_5_loss: 140.2632 - val_loss: 134.6072 - val_dense_4_loss: 166.9948 - val_dense_5_loss: 126.5103\n",
      "Epoch 17/70\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 128.4258 - dense_4_loss: 140.4492 - dense_5_loss: 125.4200 - val_loss: 124.2345 - val_dense_4_loss: 157.8882 - val_dense_5_loss: 115.8211\n",
      "Epoch 18/70\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 121.3373 - dense_4_loss: 128.0575 - dense_5_loss: 119.6573 - val_loss: 116.9035 - val_dense_4_loss: 145.9442 - val_dense_5_loss: 109.6433\n",
      "Epoch 19/70\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 119.0165 - dense_4_loss: 134.8191 - dense_5_loss: 115.0658 - val_loss: 118.7655 - val_dense_4_loss: 140.9109 - val_dense_5_loss: 113.2291\n",
      "Epoch 20/70\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 105.9691 - dense_4_loss: 126.1491 - dense_5_loss: 100.9241 - val_loss: 114.4879 - val_dense_4_loss: 139.5997 - val_dense_5_loss: 108.2100\n",
      "Epoch 21/70\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 116.5771 - dense_4_loss: 123.7961 - dense_5_loss: 114.7723 - val_loss: 111.2271 - val_dense_4_loss: 136.8506 - val_dense_5_loss: 104.8213\n",
      "Epoch 22/70\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 88.4212 - dense_4_loss: 100.7495 - dense_5_loss: 85.3391 - val_loss: 112.4444 - val_dense_4_loss: 130.3555 - val_dense_5_loss: 107.9666\n",
      "Epoch 23/70\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 100.1832 - dense_4_loss: 113.8762 - dense_5_loss: 96.7600 - val_loss: 109.4967 - val_dense_4_loss: 132.6320 - val_dense_5_loss: 103.7129\n",
      "Epoch 24/70\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 97.2260 - dense_4_loss: 99.4280 - dense_5_loss: 96.6755 - val_loss: 109.4920 - val_dense_4_loss: 130.8311 - val_dense_5_loss: 104.1572\n",
      "Epoch 25/70\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 109.2584 - dense_4_loss: 116.0744 - dense_5_loss: 107.5544 - val_loss: 106.3874 - val_dense_4_loss: 124.8857 - val_dense_5_loss: 101.7629\n",
      "Epoch 26/70\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 96.5184 - dense_4_loss: 102.9425 - dense_5_loss: 94.9123 - val_loss: 112.6416 - val_dense_4_loss: 124.0564 - val_dense_5_loss: 109.7879\n",
      "Epoch 27/70\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 95.0622 - dense_4_loss: 109.3960 - dense_5_loss: 91.4788 - val_loss: 116.1820 - val_dense_4_loss: 123.4335 - val_dense_5_loss: 114.3691\n",
      "Epoch 28/70\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 83.6169 - dense_4_loss: 91.9638 - dense_5_loss: 81.5302 - val_loss: 104.0509 - val_dense_4_loss: 125.3066 - val_dense_5_loss: 98.7369\n",
      "Epoch 29/70\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 99.9705 - dense_4_loss: 121.8712 - dense_5_loss: 94.4953 - val_loss: 107.0015 - val_dense_4_loss: 121.6990 - val_dense_5_loss: 103.3271\n",
      "Epoch 30/70\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 100.0390 - dense_4_loss: 106.9497 - dense_5_loss: 98.3113 - val_loss: 101.9038 - val_dense_4_loss: 116.1378 - val_dense_5_loss: 98.3453\n",
      "Epoch 31/70\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 80.4854 - dense_4_loss: 92.3162 - dense_5_loss: 77.5277 - val_loss: 101.7560 - val_dense_4_loss: 118.9106 - val_dense_5_loss: 97.4673\n",
      "Epoch 32/70\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 81.2740 - dense_4_loss: 89.9012 - dense_5_loss: 79.1171 - val_loss: 125.0051 - val_dense_4_loss: 128.0661 - val_dense_5_loss: 124.2398\n",
      "Epoch 33/70\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 94.6756 - dense_4_loss: 103.1230 - dense_5_loss: 92.5638 - val_loss: 103.9688 - val_dense_4_loss: 118.6520 - val_dense_5_loss: 100.2981\n",
      "Epoch 34/70\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 95.2033 - dense_4_loss: 100.9943 - dense_5_loss: 93.7556 - val_loss: 98.0699 - val_dense_4_loss: 114.5296 - val_dense_5_loss: 93.9550\n",
      "Epoch 35/70\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 102.6020 - dense_4_loss: 113.3998 - dense_5_loss: 99.9025 - val_loss: 113.7836 - val_dense_4_loss: 111.9780 - val_dense_5_loss: 114.2349\n",
      "Epoch 36/70\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 87.3560 - dense_4_loss: 92.2724 - dense_5_loss: 86.1269 - val_loss: 103.2021 - val_dense_4_loss: 110.5782 - val_dense_5_loss: 101.3580\n",
      "Epoch 37/70\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 86.6100 - dense_4_loss: 96.1777 - dense_5_loss: 84.2180 - val_loss: 101.9076 - val_dense_4_loss: 110.5815 - val_dense_5_loss: 99.7391\n",
      "Epoch 38/70\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 84.8443 - dense_4_loss: 98.1556 - dense_5_loss: 81.5164 - val_loss: 99.1543 - val_dense_4_loss: 111.9635 - val_dense_5_loss: 95.9520\n",
      "Epoch 39/70\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 84.3231 - dense_4_loss: 93.9160 - dense_5_loss: 81.9249 - val_loss: 93.8670 - val_dense_4_loss: 107.0664 - val_dense_5_loss: 90.5672\n",
      "Epoch 40/70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 6ms/step - loss: 80.8814 - dense_4_loss: 87.3127 - dense_5_loss: 79.2736 - val_loss: 94.7990 - val_dense_4_loss: 104.7781 - val_dense_5_loss: 92.3042\n",
      "Epoch 41/70\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 73.2181 - dense_4_loss: 83.7930 - dense_5_loss: 70.5744 - val_loss: 105.8288 - val_dense_4_loss: 109.5689 - val_dense_5_loss: 104.8938\n",
      "Epoch 42/70\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 86.6369 - dense_4_loss: 91.0326 - dense_5_loss: 85.5380 - val_loss: 97.3136 - val_dense_4_loss: 102.7119 - val_dense_5_loss: 95.9640\n",
      "Epoch 43/70\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 81.2271 - dense_4_loss: 92.8929 - dense_5_loss: 78.3106 - val_loss: 91.8076 - val_dense_4_loss: 104.4358 - val_dense_5_loss: 88.6505\n",
      "Epoch 44/70\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 85.9435 - dense_4_loss: 100.3410 - dense_5_loss: 82.3441 - val_loss: 107.6786 - val_dense_4_loss: 110.9389 - val_dense_5_loss: 106.8635\n",
      "Epoch 45/70\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 82.5912 - dense_4_loss: 97.1348 - dense_5_loss: 78.9554 - val_loss: 90.0336 - val_dense_4_loss: 104.0242 - val_dense_5_loss: 86.5359\n",
      "Epoch 46/70\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 77.9963 - dense_4_loss: 85.1977 - dense_5_loss: 76.1959 - val_loss: 90.0245 - val_dense_4_loss: 105.7682 - val_dense_5_loss: 86.0886\n",
      "Epoch 47/70\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 78.3782 - dense_4_loss: 87.0065 - dense_5_loss: 76.2212 - val_loss: 89.2263 - val_dense_4_loss: 101.0683 - val_dense_5_loss: 86.2659\n",
      "Epoch 48/70\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 79.0097 - dense_4_loss: 87.2917 - dense_5_loss: 76.9392 - val_loss: 113.8519 - val_dense_4_loss: 98.3167 - val_dense_5_loss: 117.7357\n",
      "Epoch 49/70\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 90.2378 - dense_4_loss: 78.4535 - dense_5_loss: 93.1839 - val_loss: 92.7563 - val_dense_4_loss: 97.9299 - val_dense_5_loss: 91.4629\n",
      "Epoch 50/70\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 80.7032 - dense_4_loss: 98.1878 - dense_5_loss: 76.3320 - val_loss: 86.5090 - val_dense_4_loss: 98.6941 - val_dense_5_loss: 83.4627\n",
      "Epoch 51/70\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 74.1760 - dense_4_loss: 86.0569 - dense_5_loss: 71.2058 - val_loss: 102.5112 - val_dense_4_loss: 96.1837 - val_dense_5_loss: 104.0930\n",
      "Epoch 52/70\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 84.4271 - dense_4_loss: 86.4005 - dense_5_loss: 83.9337 - val_loss: 99.4575 - val_dense_4_loss: 95.2587 - val_dense_5_loss: 100.5072\n",
      "Epoch 53/70\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 73.3305 - dense_4_loss: 88.0699 - dense_5_loss: 69.6457 - val_loss: 94.8534 - val_dense_4_loss: 101.7592 - val_dense_5_loss: 93.1270\n",
      "Epoch 54/70\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 65.5519 - dense_4_loss: 73.4895 - dense_5_loss: 63.5675 - val_loss: 94.5875 - val_dense_4_loss: 102.1974 - val_dense_5_loss: 92.6850\n",
      "Epoch 55/70\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 81.2953 - dense_4_loss: 94.8754 - dense_5_loss: 77.9002 - val_loss: 83.5374 - val_dense_4_loss: 92.2148 - val_dense_5_loss: 81.3681\n",
      "Epoch 56/70\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 84.5447 - dense_4_loss: 95.6185 - dense_5_loss: 81.7763 - val_loss: 96.4658 - val_dense_4_loss: 93.0632 - val_dense_5_loss: 97.3164\n",
      "Epoch 57/70\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 73.0065 - dense_4_loss: 85.5828 - dense_5_loss: 69.8625 - val_loss: 87.2915 - val_dense_4_loss: 94.4664 - val_dense_5_loss: 85.4977\n",
      "Epoch 58/70\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 73.7059 - dense_4_loss: 81.4425 - dense_5_loss: 71.7717 - val_loss: 112.4550 - val_dense_4_loss: 138.9735 - val_dense_5_loss: 105.8253\n",
      "Epoch 59/70\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 76.8187 - dense_4_loss: 85.9374 - dense_5_loss: 74.5390 - val_loss: 81.2372 - val_dense_4_loss: 91.6363 - val_dense_5_loss: 78.6374\n",
      "Epoch 60/70\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 86.9011 - dense_4_loss: 83.8030 - dense_5_loss: 87.6757 - val_loss: 81.3029 - val_dense_4_loss: 89.1411 - val_dense_5_loss: 79.3433\n",
      "Epoch 61/70\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 73.6363 - dense_4_loss: 82.0774 - dense_5_loss: 71.5261 - val_loss: 92.6227 - val_dense_4_loss: 110.5660 - val_dense_5_loss: 88.1369\n",
      "Epoch 62/70\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 68.6378 - dense_4_loss: 79.3752 - dense_5_loss: 65.9535 - val_loss: 80.2954 - val_dense_4_loss: 96.7184 - val_dense_5_loss: 76.1897\n",
      "Epoch 63/70\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 72.1496 - dense_4_loss: 86.2620 - dense_5_loss: 68.6216 - val_loss: 90.6988 - val_dense_4_loss: 88.6358 - val_dense_5_loss: 91.2145\n",
      "Epoch 64/70\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 76.1045 - dense_4_loss: 86.1494 - dense_5_loss: 73.5932 - val_loss: 77.8085 - val_dense_4_loss: 87.3868 - val_dense_5_loss: 75.4139\n",
      "Epoch 65/70\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 60.1984 - dense_4_loss: 68.7768 - dense_5_loss: 58.0538 - val_loss: 79.8117 - val_dense_4_loss: 89.9854 - val_dense_5_loss: 77.2683\n",
      "Epoch 66/70\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 69.0189 - dense_4_loss: 81.3524 - dense_5_loss: 65.9355 - val_loss: 79.0480 - val_dense_4_loss: 87.7805 - val_dense_5_loss: 76.8649\n",
      "Epoch 67/70\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 84.1014 - dense_4_loss: 90.5363 - dense_5_loss: 82.4927 - val_loss: 79.2163 - val_dense_4_loss: 97.4459 - val_dense_5_loss: 74.6589\n",
      "Epoch 68/70\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 61.7718 - dense_4_loss: 75.1129 - dense_5_loss: 58.4366 - val_loss: 89.0920 - val_dense_4_loss: 84.8633 - val_dense_5_loss: 90.1492\n",
      "Epoch 69/70\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 69.9182 - dense_4_loss: 79.9083 - dense_5_loss: 67.4207 - val_loss: 79.1582 - val_dense_4_loss: 97.6710 - val_dense_5_loss: 74.5300\n",
      "Epoch 70/70\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 71.0023 - dense_4_loss: 84.4125 - dense_5_loss: 67.6497 - val_loss: 79.0390 - val_dense_4_loss: 92.1539 - val_dense_5_loss: 75.7603\n"
     ]
    }
   ],
   "source": [
    "#callbacks\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "callback_list = [ReduceLROnPlateau(monitor='val_loss',factor=0.1,patience=10)]\n",
    "\n",
    "#compile model\n",
    "model.compile(loss=['mse','mse'],loss_weights=[0.2,0.8], optimizer='RMSprop')\n",
    "#fit model\n",
    "history = model.fit([x_train1,x_train2],[y_train,y_train],epochs=70, batch_size=32, callbacks=callback_list,\n",
    "                    validation_data=([x_test1,x_test2],[y_test,y_test]))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
